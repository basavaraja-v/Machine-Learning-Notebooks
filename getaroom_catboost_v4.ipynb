{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royaldevops/Machine-Learning-Notebooks/blob/main/getaroom_catboost_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZNFgXcG03Yk"
      },
      "source": [
        "## $$1.\\ Data\\ Preparation$$\n",
        "### 1.1 CatBoost installation\n",
        "If you have not already installed CatBoost, you can do so by running '!pip install catboost' command.  \n",
        "  \n",
        "Also you should install ipywidgets package and run special command before launching jupyter notebook to draw plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfolZ2UQjMnK"
      },
      "outputs": [],
      "source": [
        "# !conda install --yes catboost\n",
        "!pip install catboost\n",
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "!pip3 install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfGnvK2K1Ibi"
      },
      "source": [
        "### 1.2 Import necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIHIyXuH34at"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor, Pool, metrics, cv, MetricVisualizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0saQQ0J01WMt"
      },
      "source": [
        "### 1.3 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzYgmvZgYJbP"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A77o8nXj1eJr"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwoQZO-71hIB"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iod-7XO2Q6K"
      },
      "source": [
        "### 1.4 Feature Preparation\n",
        "First of all let's check how many absent values do we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrLOE68Y3uHn"
      },
      "outputs": [],
      "source": [
        "#Let us drop the Property_ID \n",
        "train_df.drop('Property_ID',axis=1,inplace=True)\n",
        "Property_IDs = test_df.pop(\"Property_ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6EbFKpy3b1q"
      },
      "outputs": [],
      "source": [
        "#list out the categorical features \n",
        "cat_features = list(train_df.select_dtypes(include=['object','category']).columns)\n",
        "cat_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5eQMfHA2XWv"
      },
      "outputs": [],
      "source": [
        "null_value_stats = train_df.isnull().sum(axis=0)\n",
        "null_value_stats[null_value_stats != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5fkkKp54aDY"
      },
      "outputs": [],
      "source": [
        "#from the above observations we had null values in categorical features fill those with string 'NaN'\n",
        "train_df['Furnishing'] =train_df['Furnishing'].fillna('NaN') \n",
        "train_df['Crime_Rate'] =train_df['Crime_Rate'].fillna('NaN') \n",
        "train_df['Dust_and_Noise'] =train_df['Dust_and_Noise'].fillna('NaN') \n",
        "\n",
        "test_df['Furnishing'] =test_df['Furnishing'].fillna('NaN') \n",
        "test_df['Crime_Rate'] =test_df['Crime_Rate'].fillna('NaN') \n",
        "test_df['Dust_and_Noise'] =test_df['Dust_and_Noise'].fillna('NaN') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeipRHPA4uCt"
      },
      "outputs": [],
      "source": [
        "null_value_stats = train_df.isnull().sum(axis=0)\n",
        "null_value_stats[null_value_stats != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlEK8AO53FQu"
      },
      "outputs": [],
      "source": [
        "train_df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHiH05y-7zoU"
      },
      "source": [
        "Now let's separate features and label variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wqTwG8u71Sg"
      },
      "outputs": [],
      "source": [
        "X = train_df.drop('Habitability_score', axis=1)\n",
        "y = train_df.Habitability_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6S7ay1l8Hkz"
      },
      "source": [
        "### 1.5 Data Splitting\n",
        "Let's split the train data into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9BdlOdl8K2s"
      },
      "outputs": [],
      "source": [
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_test = test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBlnnoX47jHT"
      },
      "source": [
        "### 1.6 Common Functions\n",
        "Define common functions for metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyoKFO8ukaLF"
      },
      "outputs": [],
      "source": [
        "def rmlse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(tf.math.log(y_pred + 1) - tf.math.log(y_true + 1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnm4GaLgjElT"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, x_val, y_val):\n",
        "    y_pred = model.predict(x_val)\n",
        "    r2 = metrics.r2_score(y_val, y_pred)\n",
        "    mse = metrics.mean_squared_error(y_val, y_pred)\n",
        "    mae = metrics.mean_absolute_error(y_val, y_pred)\n",
        "    msle = metrics.mean_squared_log_error(y_val, y_pred)\n",
        "    mape = np.mean(tf.keras.metrics.mean_absolute_percentage_error(y_val, y_pred).numpy())\n",
        "    rmse = np.sqrt(mse)\n",
        "    rmlse_score = rmlse(y_val, y_pred).numpy()\n",
        "    print(\"R2 Score:\", r2)\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"MSLE:\", msle)\n",
        "    print(\"MAPE\", mape)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"RMLSE\", rmlse_score)\n",
        "    # return {\"r2\": r2, \"mse\": mse, \"mae\": mae, \"msle\": msle, \"mape\": mape, \"rmse\": rmse, \"rmlse\": rmlse_score}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "homy6cpyKFxn"
      },
      "outputs": [],
      "source": [
        "def submit(model, X, ids, file_path):\n",
        "    Habitability_score = model.predict(X)\n",
        "    submission = pd.DataFrame({\"Property_ID\": ids, \"Habitability_score\": Habitability_score.reshape(-1)})\n",
        "    submission.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o31FecuSFKhV"
      },
      "source": [
        "## $$2.\\ CatBoost\\ Model$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Ji5F6PIKwQ"
      },
      "source": [
        "### 2.1 Model Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9c5Llo_A5RX"
      },
      "outputs": [],
      "source": [
        "default_param_model = CatBoostRegressor(train_dir='default_param_model')\n",
        "default_param_model.fit(\n",
        "    X_train, y_train,\n",
        "    cat_features=cat_features,\n",
        "    eval_set=(X_validation, y_validation),\n",
        "    verbose = 100,\n",
        "    plot = True\n",
        ");\n",
        "# evaluate(default_param_model, X_validation, y_validation)\n",
        "default_param_model.score(X_validation, y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U58UabdwFKhc"
      },
      "outputs": [],
      "source": [
        "model = CatBoostRegressor(l2_leaf_reg=3, learning_rate=0.09,iterations=292,depth=12,train_dir='l2_leaf_reg_4_5')\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    cat_features=cat_features,\n",
        "    eval_set=(X_validation, y_validation),\n",
        "    verbose = 100,\n",
        "    plot = True\n",
        ");\n",
        "# evaluate(model, X_validation, y_validation)\n",
        "model.score(X_validation, y_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVNML4sVFKhf"
      },
      "source": [
        "### 2.2 Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D0j92_yFKhg"
      },
      "outputs": [],
      "source": [
        "MetricVisualizer(['default_param_model','l2_leaf_reg_4_5']).start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPOZbBanFKhh"
      },
      "source": [
        "### 2.3 Model Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmwp_TLAFKhj"
      },
      "outputs": [],
      "source": [
        "def model_cv(model):\n",
        "  cv_params = model.get_params()\n",
        "  if 'od_type' in cv_params:\n",
        "    del cv_params['od_type']\n",
        "  cv_data = cv(\n",
        "      Pool(X, y, cat_features=cat_features),\n",
        "      cv_params,\n",
        "      plot=True,\n",
        "      verbose = 100,\n",
        "      shuffle=True,\n",
        "  )\n",
        "  print('Best validation RMSE score: {:.2f}Â±{:.2f} on step {}'.format(\n",
        "    np.max(cv_data['test-RMSE-mean']),\n",
        "    cv_data['test-RMSE-std'][np.argmax(cv_data['test-RMSE-mean'])],\n",
        "    np.argmax(cv_data['test-RMSE-mean'])))\n",
        "  print('Precise validation RMSE score: {}'.format(np.max(cv_data['test-RMSE-mean'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbljFKXrFKhn"
      },
      "outputs": [],
      "source": [
        "model_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dENIdmgaFKhn"
      },
      "source": [
        "Now we have values of our loss functions at each boosting step averaged by 3 folds, which should provide us with a more accurate estimation of our model performance:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fp8-6v_FKhp"
      },
      "source": [
        "### 2.3 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9DLz9YiFKhp"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model):\n",
        "    # Create a dataframe of feature importance \n",
        "    df_feature_importance = pd.DataFrame(model.get_feature_importance(prettified=True))\n",
        "    #plotting feature importance\n",
        "    plt.figure(figsize=(12, 6));\n",
        "    feature_plot= sns.barplot(x=\"Importances\", y=\"Feature Id\", data=df_feature_importance,palette=\"cool\");\n",
        "    plt.title('features importance');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvBeEgB8FKhq"
      },
      "outputs": [],
      "source": [
        "feature_importance(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjDf04F2FKhr"
      },
      "source": [
        "From the above plot we can see that :\n",
        "\n",
        "Furnishing, Neighborhood Review and Power Backup score has a major impact Habitability score followed by\n",
        "Property Area, Crime Rate, Dust and Noise, Water Supply, Number of Windows, Property Type, Traffic Desncity Score.\n",
        "Air Quality Index, Frequency of powercuts and number of doors are not much significant in the prediction of Habitability scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEqo2MnwFKhv"
      },
      "source": [
        "### 2.3 Model Applying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aACi6HZGFKhw"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(min(predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXGy1a-7FKhx"
      },
      "source": [
        "## $$3.\\ CatBoost\\ Features$$\n",
        "Let's define some params and create `Pool` for more convenience. It stores all information about dataset (features, labeles, categorical features indices, weights and and much more)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJbV_VycFKhx"
      },
      "outputs": [],
      "source": [
        "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
        "validate_pool = Pool(X_validation, y_validation, cat_features=cat_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AavHyE4FKh3"
      },
      "outputs": [],
      "source": [
        "select_features_model = CatBoostRegressor()\n",
        "selected_features = select_features_model.select_features(train_pool,plot=True,verbose=1000,num_features_to_select=10,features_for_select='0-12')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysDHCYNVFKh6"
      },
      "outputs": [],
      "source": [
        "selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClssO7fTFKh7"
      },
      "outputs": [],
      "source": [
        "evaluate(select_features_model, X_validation, y_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0CrpYcFKh8"
      },
      "source": [
        "### 3.1 Using the best model\n",
        "If you essentially have a validation set, it's always better to use the `use_best_model` parameter during training. By default, this parameter is enabled. If it is enabled, the resulting trees ensemble is shrinking to the best iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5jPzakLFKiA"
      },
      "outputs": [],
      "source": [
        "params = {'use_best_model': False}\n",
        "simple_model = CatBoostRegressor(**params)\n",
        "simple_model.fit(train_pool, eval_set=validate_pool,verbose=500)\n",
        "\n",
        "best_model_params = params.copy()\n",
        "best_model_params.update({\n",
        "    'use_best_model': True\n",
        "})\n",
        "best_model = CatBoostRegressor(**best_model_params)\n",
        "best_model.fit(train_pool, eval_set=validate_pool,verbose=500);\n",
        "\n",
        "print('Simple model validation R2 Score: {:.4}'.format(\n",
        "    metrics.r2_score(y_validation, simple_model.predict(X_validation))\n",
        "))\n",
        "print('')\n",
        "\n",
        "print('Best model validation R2 Score: {:.4}'.format(\n",
        "    metrics.r2_score(y_validation, best_model.predict(X_validation))\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlyinVTgFKiE"
      },
      "source": [
        "# $$4.\\ Parameters\\ Tuning$$\n",
        "While you could always select optimal number of iterations (boosting steps) by cross-validation and learning curve plots, it is also important to play with some of model parameters, and we would like to pay some special attention to `l2_leaf_reg` and `learning_rate`.\n",
        "\n",
        "In this section, we'll select these parameters using the **`grid_search`** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9kMuVhsFKiJ"
      },
      "outputs": [],
      "source": [
        "# grid_model = CatBoostRegressor()\n",
        "# grid = {'learning_rate': [0.08],'iterations': [1500],'depth': [8,10,12,14,16],\n",
        "#         'l2_leaf_reg': [4,4.5,5]}\n",
        "\n",
        "# grid_search_result = grid_model.grid_search(grid, train_pool, plot=True, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0mGwNuDFKiL"
      },
      "outputs": [],
      "source": [
        "# grid_search_result['params']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpzElCGHFKiL"
      },
      "outputs": [],
      "source": [
        "# evaluate(grid_model, X_validation, y_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGdTGxUaFKiM"
      },
      "source": [
        "In this section, we'll select these parameters using the **`optuna`** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNBgduw5FKiN"
      },
      "outputs": [],
      "source": [
        "# !pip3 install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5vAexWIFKiN"
      },
      "outputs": [],
      "source": [
        "# import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRA618kRFKiN"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 0.4\n",
        "RANDOM_SEED = 1\n",
        "EARLY_STOPPING_ROUND = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZj3U4IhFKiP"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    param = {}\n",
        "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.001, 0.02, 0.001)\n",
        "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
        "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
        "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
        "    param['grow_policy'] = 'Depthwise'\n",
        "    param['iterations'] = 10000\n",
        "    param['use_best_model'] = True\n",
        "    param['eval_metric'] = 'RMSE'\n",
        "    param['od_type'] = 'iter'\n",
        "    param['od_wait'] = 20\n",
        "    param['random_state'] = RANDOM_SEED\n",
        "    param['logging_level'] = 'Silent'\n",
        "    \n",
        "    regressor = CatBoostRegressor(**param)\n",
        "\n",
        "    regressor.fit(X_train.copy(), y_train.copy(),\n",
        "                  eval_set=[(X_validation.copy(), y_validation.copy())],\n",
        "                  early_stopping_rounds=EARLY_STOPPING_ROUND,cat_features=cat_features)\n",
        "    loss = mean_squared_error(y_validation, regressor.predict(X_validation.copy()))\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZlMqtfLFKiP"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# study = optuna.create_study(study_name=f'catboost-seed{RANDOM_SEED}')\n",
        "# study.optimize(objective, n_trials=10000, n_jobs=-1, timeout=24000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X2B0b5NFKiQ"
      },
      "outputs": [],
      "source": [
        "# study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCiVfvO_FKiQ"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEVsFDm1FKiQ"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open('best_params_v1.json', 'w') as f:\n",
        "#   json.dump(study.best_params, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKK6lmYrFKiQ"
      },
      "outputs": [],
      "source": [
        "# optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxyNv7ePFKiR"
      },
      "outputs": [],
      "source": [
        "# optuna.visualization.plot_slice(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPDpXj6PFKiR"
      },
      "outputs": [],
      "source": [
        "# optuna.visualization.plot_contour(study, params=['learning_rate',\n",
        "#                                                  'min_child_samples',\n",
        "#                                                  'depth',\n",
        "#                                                  'l2_leaf_reg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwO2q-TMFKiR"
      },
      "outputs": [],
      "source": [
        "# optuna.visualization.plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f03lWIGgFKiR"
      },
      "outputs": [],
      "source": [
        "# optuna.visualization.plot_edf(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9bdQV04FKiS"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "optimized_regressor = CatBoostRegressor(learning_rate=0.015, \n",
        "                                        depth=15, \n",
        "                                        l2_leaf_reg=4.0, \n",
        "                                        min_child_samples=1,\n",
        "                                        grow_policy='Depthwise',\n",
        "                                        use_best_model=True,\n",
        "                                        eval_metric='RMSE',\n",
        "                                        od_type='iter',\n",
        "                                        od_wait=20,\n",
        "                                        random_state=RANDOM_SEED,)\n",
        "optimized_regressor.fit(X_train.copy(), y_train.copy(),\n",
        "                        eval_set=[(X_validation.copy(), y_validation.copy())],\n",
        "                        early_stopping_rounds=EARLY_STOPPING_ROUND,cat_features=cat_features,\n",
        "                                        verbose=200,\n",
        "                                        plot=True)\n",
        "pred_train = optimized_regressor.predict(X_train.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EYKxtFSFKiS"
      },
      "outputs": [],
      "source": [
        "print('optimized model validation R2 Score: {:.4}'.format(\n",
        "    metrics.r2_score(y_validation, optimized_regressor.predict(X_validation))\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzxCwBkoFKiS"
      },
      "outputs": [],
      "source": [
        "model_cv(optimized_regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNlPaQCrFKiT"
      },
      "outputs": [],
      "source": [
        "feature_importance(optimized_regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygMy31zBFKiV"
      },
      "outputs": [],
      "source": [
        "submit(optimized_regressor, X_test, Property_IDs, 'submitioncatboost.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}